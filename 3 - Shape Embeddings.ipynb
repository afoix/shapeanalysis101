{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca54f24",
   "metadata": {},
   "source": [
    "## Part 3: Learned shape embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7dab27",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to use supervised contrastive learning to create an embedding space for objects described as collections of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4111daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from shape_embeddings.data_handling import get_MEF_loader, get_MEF_loaders\n",
    "from shape_embeddings.model import SpatialTransformer3d, SpatialTransformerkd\n",
    "from shape_embeddings.utils import Center, RandomCoordsFlip, RandomNoise, show_image, run_logistic_regression, visualize_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38173523",
   "metadata": {},
   "source": [
    "### 0. Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88031d54",
   "metadata": {},
   "source": [
    "**0.1** The first step needed to train a neural network model is to implement a dataset. A dataset is a class from which data can be sampled for training. This class usually handels most of the data preprocessing including data augmentation. Since we are not focusing on data handling, we already implemented a custom dataset in the lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47e7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEFDataset(Dataset):\n",
    "    def __init__(self, dataset, transforms=None):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.base_transform = Center()\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def apply_transforms(self, pts):\n",
    "        for transform in self.transforms:\n",
    "            pts = transform(pts)\n",
    "        return pts\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label, pts = self.dataset[idx]\n",
    "        pts = self.base_transform(pts)\n",
    "        if self.transforms:\n",
    "            pts = self.apply_transforms(pts)\n",
    "        return (label, pts.astype(np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cb4e6a",
   "metadata": {},
   "source": [
    "**0.2** The next step is to initialize a data loader, such that samples can be drawn during training. The function below first loads the data, partitions it and initializes two MEFDatasets. The datasets are then given data loaders  for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e19c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MEF_loaders(path_to_dataset, batch_size=100, transforms=None):\n",
    "    # Load data from storage\n",
    "    mef_data = np.load(path_to_dataset, allow_pickle=True).item()\n",
    "    data = []\n",
    "    for key, pts in mef_data.items():\n",
    "         # we asign label 0 to the wild-type and 1 to the lamin deficient cell\n",
    "        label = 0 if 'wildtype' in key else 1\n",
    "        data += [(label, pts.T)]\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    # Split data into training and validation set\n",
    "    split_index = int(len(data) * 0.75)\n",
    "    train_data = MEFDataset(data[:split_index], transforms)\n",
    "    val_data = MEFDataset(data[split_index:])\n",
    "\n",
    "    train_loader = DataLoader(train_data,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ad506",
   "metadata": {},
   "source": [
    "### 1. The PointNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c76c18",
   "metadata": {},
   "source": [
    "Point clouds are unordered sets of points. We represent them as tensors of shape [num_batches, dim_points, num_points]. The points in such a tensor can be reordered/permuted without changing the structure of the data. This is different from images, in which a reordering of pixels would change the image.\n",
    "\n",
    "We will use a neural network called PointNet (https://arxiv.org/pdf/1612.00593.pdf) that is specifically designed for point clouds. It accounts for the permutation invariance of the data by processing each point identically and separately in its inital stage. The input to the network are the points in their (x,y) coordinates. The idea is to use a single function to encode each point and then use a pooling operation that summarizes the obtained information. The network learns to select and encode shape informative points. The final pooling and fully connected layers aggregate this information into a global shape descriptor (embedding vector). During training, the embedding vector is further processed using a 'projection head' that compresses the embedding into a lower dimensional space in which the loss is computed. During inference, the embedding vector can be classified by training a linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b26db",
   "metadata": {},
   "source": [
    "**1.1** The cell below contains the code for the encoding part of PointNet. The module first applies a learned geometric transformation (e.g. rotation) to the input and then processses each point separately by applying convolutions, batchnorm layers and relu activation. The final max pooling operation aggregates the features into a global vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b77cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, global_feat=True, feature_transform=False):\n",
    "        super().__init__()\n",
    "        self.transformer = SpatialTransformer3d()\n",
    "        if feature_transform:\n",
    "            self.feat_transformer = SpatialTransformerkd()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(2, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        self.global_feat = global_feat\n",
    "        self.feat_transform = feature_transform\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_pts = x.size()[2]\n",
    "        trans = self.transformer(x)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = torch.bmm(x, trans)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        if self.feat_transform:\n",
    "            trans_feat = self.feat_transformer(x)\n",
    "            x = x.transpose(2, 1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2, 1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30866ee",
   "metadata": {},
   "source": [
    "**1.2** The cell below contains the code for PointNet. It first applies the encoder network from the previous cell, followed by two fully connected layers. During training, the obtained embedding vector is further processes with a projection head. The network returns the embedding vector and the projected embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ede951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 head='mlp',\n",
    "                 embed_dim=2048,\n",
    "                 feat_dim=128,\n",
    "                 feature_transform=False):\n",
    "        super().__init__()\n",
    "        self.feature_transform = feature_transform\n",
    "        self.feat = PointNetEncoder(global_feat=True,\n",
    "                                    feature_transform=feature_transform)\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 1024)\n",
    "        self.fc2 = nn.Linear(1024, embed_dim)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if head == 'linear':\n",
    "            self.head = nn.Linear(embed_dim, feat_dim)\n",
    "        elif head == 'mlp':\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(embed_dim, embed_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(embed_dim, feat_dim)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        out = F.normalize(self.head(x), dim=1)\n",
    "        return out, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ab3b70",
   "metadata": {},
   "source": [
    "### 2. Supervised constrastive loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f908db3",
   "metadata": {},
   "source": [
    "**2.1** The idea behind contrastive learning is to pull together an anchor (the sample that is processed) and a 'positive' sample (same class) in embedding space, and push apart the anchor from 'negative' samples (different class). The code in the next cell translates this idea into a supervised contrastive loss function. The inputs to the loss are the ground truth labels and the projected output of the network. The objective itself is a modified normalized temperature-scaled cross entropy loss (see https://arxiv.org/pdf/2004.11362.pdf Eq. 2 & 3 for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b697925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/HobbitLong/SupContrast/blob/master/losses.py\n",
    "# Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07, contrast_mode='all', base_temperature=0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        batch_size = features.shape[0]\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T) \\\n",
    "                    .float() \\\n",
    "                    .to(torch.device('cuda' if features.is_cuda else 'cpu'))\n",
    "\n",
    "\n",
    "        contrast_count = features.shape[1]\n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # compute logits\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature)\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        # tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "\n",
    "        # compute mean of log-likelihood over positive\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
    "\n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        loss = loss.view(anchor_count, batch_size).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7aa24",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a02913",
   "metadata": {},
   "source": [
    "**3.1** The code below contains a simple routine to train our model. In a nutshell, data is fetched from the data loader and given to the model to process. The network outputs a projection and an embedding vector. The projection vector and the labels are given to the loss function to score the prediction. Based on this score, gradients are computed which are used to adjust the weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a88f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, criterion, optimizer, train_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    run_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        labels, points = data\n",
    "        points = points.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # process points with the model\n",
    "        outputs, embed = model(points)\n",
    "\n",
    "        # compute loss and gradients\n",
    "        loss = criterion(outputs.unsqueeze(1), labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # optimizer update: adjust network parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        run_loss += loss.item()\n",
    "\n",
    "    avg_loss = run_loss / len(train_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f061e0c7",
   "metadata": {},
   "source": [
    "**3.2** In order to assess the performance of our model during training, we use a validation set and a separate routine to score the network. The following code contains a routine that evaluates our model's performance. The first half of the function is similar to the training loop, however we don't compute gradients since we are only interested in the averaged loss on the validation set. In the second half of the function we train a linear model with embedding vectors obtained with our model to classify cells of the validation set. The averaged loss and accuracy of the linear classifier on the validation set are then returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e4267fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(model, criterion, val_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    run_loss = 0.0\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for i, data in enumerate(val_loader):\n",
    "        label, points = data\n",
    "        points = points.to(device)\n",
    "        label = label.to(device)\n",
    "        out, embed = model(points)\n",
    "        embeddings += [embed.detach().cpu().numpy()]\n",
    "        labels += [label.cpu().numpy()]\n",
    "        loss = criterion(out.unsqueeze(1), label)\n",
    "        run_loss += loss.item()\n",
    "\n",
    "    # Compute average validation loss\n",
    "    avg_loss = run_loss / len(val_loader)\n",
    "    \n",
    "    # Usa a logistic regression model to evaluate the accuracy\n",
    "    accuracy = run_logistic_regression(\n",
    "        np.concatenate(embeddings, axis=0), np.concatenate(labels)\n",
    "    )\n",
    "\n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb8cdc3",
   "metadata": {},
   "source": [
    "**3.3** We will use the VMs GPU to train the model more efficiently. Run the lines below make sure that the correct device is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44b364a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2edf8",
   "metadata": {},
   "source": [
    "**3.4** An important task is to find suitable hyperparameters to train the network. The following cell contains hyperparameters for you to modify. Your task is to find a set of suitable parameters (cell 3.4) and then run cells (3.5 & 3.6) to assess the models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e0ac65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "\n",
    "# Sampler and optimizer parameters\n",
    "batch_size = 200  # how many samples are given to the network at once\n",
    "lr = 0.0001  # learning rate\n",
    "weight_decay = 0.0001  # weight for loss regularization\n",
    "\n",
    "# Neural network parameters\n",
    "embedding_dim = 2048  # dimension of the embedding\n",
    "projection_head = 'mlp' # options ('mlp', 'linear'); Neural network applied to embedding features to compute output features\n",
    "output_dim = 128  # dimension of the network output\n",
    "feature_transform = False  # if true, spatial transformer is applied to features\n",
    "\n",
    "# Loss parameters (they should be fine but you can change them if you want)\n",
    "temp = 0.07\n",
    "contrast_mode = 'all'  # options ('all', 'one')\n",
    "base_temp = 0.07\n",
    "\n",
    "# Training parameters\n",
    "epochs = 1  # how many epochs to run the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d6bb65",
   "metadata": {},
   "source": [
    "**3.5** Run the lines below to initalize all the elements required to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68516c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = 'data/MEF_LMNA/mef_data.npy'\n",
    "\n",
    "# Initialize dataloaders\n",
    "train_loader, val_loader = get_MEF_loaders(path_to_data, batch_size=batch_size)\n",
    "                \n",
    "# Initialize neural network\n",
    "model = PointNet(head=projection_head,\n",
    "                embed_dim=embedding_dim,\n",
    "                feat_dim=output_dim,\n",
    "                feature_transform=feature_transform).to(device)\n",
    "\n",
    "# Initialize criterion\n",
    "criterion = SupConLoss(temperature=temp,\n",
    "                       contrast_mode=contrast_mode,\n",
    "                       base_temperature=base_temp)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=lr,\n",
    "                       weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e290d7",
   "metadata": {},
   "source": [
    "**3.6** The code below contains the global training routine. Our baseline will be the performance of a model with random weights. We will then train this model for a specified number of epochs. In each epoch the network will iterate once through the whole training set in order to adjust its parameters. After completing one such iteration, the model is evaluated using the validation loop. We will keep track of the best performing parameters, in case the network starts to overfit on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fafb6f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy:  0.835\n",
      "[epoch 0] train loss:  5.269\n",
      "[epoch 0] val loss / accuracy:  5.246 / 0.741\n",
      "Best model accuracy:  0.741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "accuracy, loss = validation_loop(model, criterion, val_loader)\n",
    "print('Baseline accuracy:  %.3f' % (accuracy))\n",
    "\n",
    "# Run training\n",
    "best_accuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    loss = train_loop(model, criterion, optimizer, train_loader)\n",
    "    print('[epoch {}] train loss:  {:.3f}'.format(epoch, loss))\n",
    "    \n",
    "    accuracy, val_loss = validation_loop(model, criterion, val_loader)\n",
    "    print('[epoch {}] val loss / accuracy:  {:.3f} / {:.3f}'.format(epoch, val_loss, accuracy))\n",
    "    \n",
    "    if best_accuracy < accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = model.state_dict()\n",
    "\n",
    "print('Best model accuracy:  {:.3f}'.format(best_accuracy))\n",
    "model.load_state_dict(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac156bf7",
   "metadata": {},
   "source": [
    "### 4. Visualize embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc1eba6",
   "metadata": {},
   "source": [
    "In the last part, we will visualize the learned representations and try to identify wild-type/lamin deficient cells using k-means clustering. In order to do that we first process the whole dataset with the trained model and map each cell to its corresponding embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb06cad",
   "metadata": {},
   "source": [
    "**4.1** Process the whole dataset using the trained model from the previous section. The output should be a tensor of shape [number of cells in the dataset, embedding dimension] that contains the embeddings and a tensor of shape [number of cells in the dataset] with the corresponding labels. Hint: have another look at the 'validation_loop' function in (3.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a64a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointNet(\n",
       "  (feat): PointNetEncoder(\n",
       "    (transformer): SpatialTransformer3d(\n",
       "      (conv1): Conv1d(2, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc3): Linear(in_features=256, out_features=4, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Conv1d(2, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "  (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = get_MEF_loader('data/MEF_LMNA/mef_data.npy')\n",
    "model.eval()\n",
    "\n",
    "# Desired output:\n",
    "# Add your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dbc074",
   "metadata": {},
   "source": [
    "**4.2** Apply principal component analysis (PCA) to the embeddings and visualize it by projecting onto the first two principal components. Use labels to assign colors to the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "306ec1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d50355a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired output:\n",
    "# Add your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45becd7c",
   "metadata": {},
   "source": [
    "**4.3** Apply k-means clustering to the embeddings and compare with the correct labels how it clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b368d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c258479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired output:\n",
    "# Add your code here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
